{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. 딥러닝 초음파 광물 예측.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNoWbfkjf0/lWF4yGvbD4Q+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"_ksEg8xWyeds","executionInfo":{"status":"ok","timestamp":1659854466156,"user_tz":-540,"elapsed":436,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import numpy as np\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["!git clone https://github.com/taehojo/data.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TEPF5RaByoGi","executionInfo":{"status":"ok","timestamp":1659854466158,"user_tz":-540,"elapsed":6,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"e5011bd4-256d-4869-9b18-219d1cacdac5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'data' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/data/sonar3.csv\", header=None)\n","df.head()"],"metadata":{"id":"zy8eeNJ9yrK0","colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"status":"ok","timestamp":1659854466455,"user_tz":-540,"elapsed":300,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"d271c8ac-a731-445b-9e50-022aff43ab0e"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0       1       2       3       4       5       6       7       8   \\\n","0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n","1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n","2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n","3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n","4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n","\n","       9   ...      51      52      53      54      55      56      57  \\\n","0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n","1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n","2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n","3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n","4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n","\n","       58      59  60  \n","0  0.0090  0.0032   0  \n","1  0.0052  0.0044   0  \n","2  0.0095  0.0078   0  \n","3  0.0040  0.0117   0  \n","4  0.0107  0.0094   0  \n","\n","[5 rows x 61 columns]"],"text/html":["\n","  <div id=\"df-9f4d63d9-f1a6-45f5-ba0d-d8e9cb436c1b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>...</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>...</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>...</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>...</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>...</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 61 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f4d63d9-f1a6-45f5-ba0d-d8e9cb436c1b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9f4d63d9-f1a6-45f5-ba0d-d8e9cb436c1b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9f4d63d9-f1a6-45f5-ba0d-d8e9cb436c1b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df[60].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avO1mphoHtLU","executionInfo":{"status":"ok","timestamp":1659854468231,"user_tz":-540,"elapsed":404,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"22a09f31-9562-415f-c691-97fe7190d746"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    111\n","0     97\n","Name: 60, dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["X = df.iloc[:, 0:60]\n","y = df.iloc[:, 60]"],"metadata":{"id":"yAhZX0znIFY7","executionInfo":{"status":"ok","timestamp":1659854468231,"user_tz":-540,"elapsed":1,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, shuffle=True)"],"metadata":{"id":"ckvDb1AqLSK1","executionInfo":{"status":"ok","timestamp":1659854469214,"user_tz":-540,"elapsed":3,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(24, input_dim = 60, activation = 'relu'))\n","model.add(Dense(10, activation = 'relu'))\n","model.add(Dense(1, activation = 'sigmoid'))"],"metadata":{"id":"_hD471E_IPp4","executionInfo":{"status":"ok","timestamp":1659854377980,"user_tz":-540,"elapsed":434,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"],"metadata":{"id":"qh-eAHClIQ7B","executionInfo":{"status":"ok","timestamp":1659854379508,"user_tz":-540,"elapsed":2,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["history = model.fit(X_train, y_train, epochs = 200, batch_size=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmVo1SqnItVR","executionInfo":{"status":"ok","timestamp":1659854393945,"user_tz":-540,"elapsed":14046,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"f31eb8f8-0fd2-4944-d93f-d4d2e43de0c2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","15/15 [==============================] - 1s 2ms/step - loss: 0.7059 - accuracy: 0.5310\n","Epoch 2/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5310\n","Epoch 3/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5310\n","Epoch 4/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5310\n","Epoch 5/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5310\n","Epoch 6/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5310\n","Epoch 7/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.5310\n","Epoch 8/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.5379\n","Epoch 9/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.5448\n","Epoch 10/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.5448\n","Epoch 11/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.5724\n","Epoch 12/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6138\n","Epoch 13/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6345\n","Epoch 14/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.6621\n","Epoch 15/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.6759\n","Epoch 16/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.6828\n","Epoch 17/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7241\n","Epoch 18/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7172\n","Epoch 19/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7655\n","Epoch 20/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8414\n","Epoch 21/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8276\n","Epoch 22/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8483\n","Epoch 23/200\n","15/15 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.8069\n","Epoch 24/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8483\n","Epoch 25/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8621\n","Epoch 26/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8069\n","Epoch 27/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8552\n","Epoch 28/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8276\n","Epoch 29/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8345\n","Epoch 30/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7862\n","Epoch 31/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8207\n","Epoch 32/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8621\n","Epoch 33/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8759\n","Epoch 34/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8276\n","Epoch 35/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8759\n","Epoch 36/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8690\n","Epoch 37/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8690\n","Epoch 38/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8552\n","Epoch 39/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8759\n","Epoch 40/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8828\n","Epoch 41/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8828\n","Epoch 42/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8690\n","Epoch 43/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8897\n","Epoch 44/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.8759\n","Epoch 45/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8759\n","Epoch 46/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8897\n","Epoch 47/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.9034\n","Epoch 48/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8897\n","Epoch 49/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8897\n","Epoch 50/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8966\n","Epoch 51/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.9034\n","Epoch 52/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.9172\n","Epoch 53/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.9172\n","Epoch 54/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9310\n","Epoch 55/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.9172\n","Epoch 56/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.9103\n","Epoch 57/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9310\n","Epoch 58/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9448\n","Epoch 59/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9241\n","Epoch 60/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9379\n","Epoch 61/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9310\n","Epoch 62/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9241\n","Epoch 63/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9310\n","Epoch 64/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9241\n","Epoch 65/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9379\n","Epoch 66/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9448\n","Epoch 67/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9448\n","Epoch 68/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9517\n","Epoch 69/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9310\n","Epoch 70/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9448\n","Epoch 71/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1998 - accuracy: 0.9517\n","Epoch 72/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1906 - accuracy: 0.9379\n","Epoch 73/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9517\n","Epoch 74/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9448\n","Epoch 75/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.1779 - accuracy: 0.9586\n","Epoch 76/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9517\n","Epoch 77/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9724\n","Epoch 78/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9379\n","Epoch 79/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9241\n","Epoch 80/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9379\n","Epoch 81/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9517\n","Epoch 82/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9586\n","Epoch 83/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9517\n","Epoch 84/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9517\n","Epoch 85/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9655\n","Epoch 86/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9655\n","Epoch 87/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9586\n","Epoch 88/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9586\n","Epoch 89/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9517\n","Epoch 90/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9586\n","Epoch 91/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9655\n","Epoch 92/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.9655\n","Epoch 93/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9655\n","Epoch 94/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9724\n","Epoch 95/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9724\n","Epoch 96/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9724\n","Epoch 97/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.9793\n","Epoch 98/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9586\n","Epoch 99/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9793\n","Epoch 100/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9793\n","Epoch 101/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1126 - accuracy: 0.9931\n","Epoch 102/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9586\n","Epoch 103/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9793\n","Epoch 104/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9724\n","Epoch 105/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9862\n","Epoch 106/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9793\n","Epoch 107/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9862\n","Epoch 108/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9724\n","Epoch 109/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9793\n","Epoch 110/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.9862\n","Epoch 111/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9931\n","Epoch 112/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9931\n","Epoch 113/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9931\n","Epoch 114/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9931\n","Epoch 115/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9931\n","Epoch 116/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9931\n","Epoch 117/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9862\n","Epoch 118/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9931\n","Epoch 119/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9931\n","Epoch 120/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9931\n","Epoch 121/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9862\n","Epoch 122/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9931\n","Epoch 123/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9931\n","Epoch 124/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9931\n","Epoch 125/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9931\n","Epoch 126/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9931\n","Epoch 127/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9931\n","Epoch 128/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9931\n","Epoch 129/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9931\n","Epoch 130/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9931\n","Epoch 131/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9931\n","Epoch 132/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9931\n","Epoch 133/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9931\n","Epoch 134/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9931\n","Epoch 135/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9931\n","Epoch 136/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9931\n","Epoch 137/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 1.0000\n","Epoch 138/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9931\n","Epoch 139/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 1.0000\n","Epoch 140/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9931\n","Epoch 141/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9931\n","Epoch 142/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9931\n","Epoch 143/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 1.0000\n","Epoch 144/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 1.0000\n","Epoch 145/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9931\n","Epoch 146/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 1.0000\n","Epoch 147/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 1.0000\n","Epoch 148/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 1.0000\n","Epoch 149/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9931\n","Epoch 150/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 1.0000\n","Epoch 151/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 1.0000\n","Epoch 152/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 1.0000\n","Epoch 153/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 1.0000\n","Epoch 154/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 1.0000\n","Epoch 155/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 1.0000\n","Epoch 156/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000\n","Epoch 157/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 1.0000\n","Epoch 158/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 1.0000\n","Epoch 159/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 1.0000\n","Epoch 160/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 1.0000\n","Epoch 161/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 1.0000\n","Epoch 162/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n","Epoch 163/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000\n","Epoch 164/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 1.0000\n","Epoch 165/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 1.0000\n","Epoch 166/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 1.0000\n","Epoch 167/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 1.0000\n","Epoch 168/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 1.0000\n","Epoch 169/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 1.0000\n","Epoch 170/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 1.0000\n","Epoch 171/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000\n","Epoch 172/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 1.0000\n","Epoch 173/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n","Epoch 174/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 1.0000\n","Epoch 175/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n","Epoch 176/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000\n","Epoch 177/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n","Epoch 178/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 1.0000\n","Epoch 179/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000\n","Epoch 180/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n","Epoch 181/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 1.0000\n","Epoch 182/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 1.0000\n","Epoch 183/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 1.0000\n","Epoch 184/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 1.0000\n","Epoch 185/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 1.0000\n","Epoch 186/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n","Epoch 187/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 1.0000\n","Epoch 188/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000\n","Epoch 189/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000\n","Epoch 190/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 1.0000\n","Epoch 191/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000\n","Epoch 192/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0167 - accuracy: 1.0000\n","Epoch 193/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 1.0000\n","Epoch 194/200\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 1.0000\n","Epoch 195/200\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 1.0000\n","Epoch 196/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 1.0000\n","Epoch 197/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000\n","Epoch 198/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000\n","Epoch 199/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\n","Epoch 200/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000\n"]}]},{"cell_type":"code","source":["score = model.evaluate(X_test, y_test)\n","print('정확도: ', score[1], 'loss: ', score[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AagyytdbI1qq","executionInfo":{"status":"ok","timestamp":1659854398381,"user_tz":-540,"elapsed":423,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"4d570fe5-daa3-47cb-aeea-8a3a5df60dcc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.8730\n","정확도:  0.8730158805847168 loss:  0.676758348941803\n"]}]},{"cell_type":"code","source":["score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMr6axlnMKnY","executionInfo":{"status":"ok","timestamp":1659854400707,"user_tz":-540,"elapsed":339,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"45bef5fa-716a-46bb-e463-9c2d0a29099c"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.676758348941803, 0.8730158805847168]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# 모델 저장"],"metadata":{"id":"eBaf3XL0PmlJ"}},{"cell_type":"code","source":["model.save('stone.hdf5')"],"metadata":{"id":"ZNjox8PbMNEU","executionInfo":{"status":"ok","timestamp":1659854406340,"user_tz":-540,"elapsed":278,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, load_model"],"metadata":{"id":"sRyqpueLOdlT","executionInfo":{"status":"ok","timestamp":1659854444608,"user_tz":-540,"elapsed":5663,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["model_load = load_model('/content/stone.hdf5')"],"metadata":{"id":"cgOCPh1WOqkE","executionInfo":{"status":"ok","timestamp":1659854444609,"user_tz":-540,"elapsed":9,"user":{"displayName":"이창대","userId":"03240578003717862477"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["score = model_load.evaluate(X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lp3ZG0_iOvZd","executionInfo":{"status":"ok","timestamp":1659854484837,"user_tz":-540,"elapsed":317,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"cee4c638-3782-4104-b28a-8c4ce450bad8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9683\n"]}]},{"cell_type":"markdown","source":["# kfold 사용해보자"],"metadata":{"id":"s5lOmlnjO0s4"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"T3_un-82UJ2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/taehojo/data.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoF4G6w_UiX1","executionInfo":{"status":"ok","timestamp":1659506981458,"user_tz":-540,"elapsed":292,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"0f0cbd11-9d60-41ed-a8a0-d01691b116c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'data' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/data/sonar3.csv\", header=None)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"BmQfAVUnUkSv","executionInfo":{"status":"ok","timestamp":1659506982557,"user_tz":-540,"elapsed":8,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"63dd8223-efa4-4089-bde3-36fd1b5f364a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0       1       2       3       4       5       6       7       8   \\\n","0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n","1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n","2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n","3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n","4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n","\n","       9   ...      51      52      53      54      55      56      57  \\\n","0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n","1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n","2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n","3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n","4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n","\n","       58      59  60  \n","0  0.0090  0.0032   0  \n","1  0.0052  0.0044   0  \n","2  0.0095  0.0078   0  \n","3  0.0040  0.0117   0  \n","4  0.0107  0.0094   0  \n","\n","[5 rows x 61 columns]"],"text/html":["\n","  <div id=\"df-969df515-8a81-45c0-8e87-b19528a4cd69\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>...</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>...</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>...</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>...</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>...</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 61 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-969df515-8a81-45c0-8e87-b19528a4cd69')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-969df515-8a81-45c0-8e87-b19528a4cd69 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-969df515-8a81-45c0-8e87-b19528a4cd69');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["X = df.iloc[:, 0:60]\n","y = df.iloc[:, 60]"],"metadata":{"id":"zbWI7ronU1yY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","k = 5\n","kfold = KFold(n_splits = k, shuffle = True)"],"metadata":{"id":"vdptCpO2PtHN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc_score = []\n","\n","def model_fn():\n","  model = Sequential()\n","  model.add(Dense(24, input_dim=60, activation='relu'))\n","  model.add(Dense(10, activation='relu'))\n","  model.add(Dense(1, activation='sigmoid'))\n","  return model"],"metadata":{"id":"dEJd_nP5U-5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for train_index, test_index in kfold.split(X): # kfold.split은 인덱스를 반환해줌\n","  X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n","  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","  model = model_fn()\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n","  history = model.fit(X_train, y_train, epochs=200, batch_size=10, verbose = 0) # verbose: 함수 수행시 발생하는 상세한 정보들을 표준 출력으로 자세히 내보낼 것인가(0 은 출력하지 않고, 1은 자세히, 2는 함축적인 정보)\n","  accuracy = model.evaluate(X_test, y_test)\n","  acc_score.append(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOIgJ7aAVNSR","executionInfo":{"status":"ok","timestamp":1659507436391,"user_tz":-540,"elapsed":53284,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"21947495-5cc8-44c9-8f7b-8fef1f158e17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 8ms/step - loss: 1.2620 - accuracy: 0.7619\n","2/2 [==============================] - 0s 8ms/step - loss: 0.9197 - accuracy: 0.7857\n","2/2 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.7619\n","2/2 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.8537\n","WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6e485cf290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","2/2 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8293\n"]}]},{"cell_type":"code","source":["a = 0\n","for i in range(len(acc_score)):\n","  a += acc_score[i][1]\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pGKK8njzWCMP","executionInfo":{"status":"ok","timestamp":1659507907115,"user_tz":-540,"elapsed":281,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"1b199564-b24e-4e13-9093-4883d43aee2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.9924506545066833\n"]}]},{"cell_type":"code","source":["# 평균정확도\n","round(a / k, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaITBvCmWynM","executionInfo":{"status":"ok","timestamp":1659507922410,"user_tz":-540,"elapsed":255,"user":{"displayName":"이창대","userId":"03240578003717862477"}},"outputId":"2d2a2280-1a7c-467c-f039-ad274b55f412"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.79849"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":[""],"metadata":{"id":"VDXVDGScX7zF"},"execution_count":null,"outputs":[]}]}